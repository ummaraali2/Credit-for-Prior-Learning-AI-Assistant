{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# AI Service Deployment Notebook\n",
    "This notebook contains steps and code to test, promote, and deploy an AI Service\n",
    "capturing logic to implement RAG pattern for grounded chats.\n",
    "\n",
    "**Note:** Notebook code generated using Prompt Lab will execute successfully.\n",
    "If code is modified or reordered, there is no guarantee it will successfully execute.\n",
    "For details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Prompt Lab as a notebook.</a>\n",
    "\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
    "\n",
    "## Contents\n",
    "This notebook contains the following parts:\n",
    "\n",
    "1. Setup\n",
    "2. Initialize all the variables needed by the AI Service\n",
    "3. Define the AI service function\n",
    "4. Deploy an AI Service\n",
    "5. Test the deployed AI Service\n",
    "\n",
    "## 1. Set up the environment\n",
    "\n",
    "Before you can run this notebook, you must perform the following setup tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to WML\n",
    "This cell defines the credentials required to work with watsonx API for both the execution in the project, \n",
    "as well as the deployment and runtime execution of the function.\n",
    "\n",
    "**Action:** Provide the IBM Cloud personal API key. For details, see\n",
    "<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "029bb152-eccd-4773-9127-19266cc80496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your api key (hit enter):  ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ibm_watsonx_ai import APIClient, Credentials\n",
    "import getpass\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://au-syd.ml.cloud.ibm.com\",\n",
    "    api_key=getpass.getpass(\"Please enter your api key (hit enter): \")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f31eb9e6-27ab-48ba-82ab-5602545d5fbe"
   },
   "outputs": [],
   "source": [
    "client = APIClient(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to a space\n",
    "A space will be be used to host the promoted AI Service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "c2541acf-f337-46d4-85bc-a79858516fbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_id = \"147fa72a-7bdf-44d4-8d4f-3d5639957c01\"\n",
    "client.set.default_space(space_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promote asset(s) to space\n",
    "We will now promote assets we will need to stage in the space so that we can access their data from the AI service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "89e200e4-0147-4139-b99d-d8a315a337d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297ad839-3386-4acf-8f0a-63ab889a3bba\n"
     ]
    }
   ],
   "source": [
    "source_project_id = \"caf544a2-807e-465f-b275-81076b99a38a\"\n",
    "vector_index_id = client.spaces.promote(\"847e4983-4868-4823-a1db-d02b42f1d706\", source_project_id, space_id)\n",
    "print(vector_index_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the AI service function\n",
    "We first need to define the AI service function\n",
    "\n",
    "### 2.1 Define the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "374291c2-f4bb-40b4-a3af-1f1f49aa0dde"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"space_id\": space_id, \n",
    "    \"vector_index_id\": vector_index_id\n",
    "}\n",
    "\n",
    "def gen_ai_service(context, params = params, **custom):\n",
    "    # import dependencies\n",
    "    import json\n",
    "    from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "    from ibm_watsonx_ai.gateway import Gateway\n",
    "    from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n",
    "    from ibm_watsonx_ai import APIClient, Credentials\n",
    "    import os\n",
    "    import requests\n",
    "    import re\n",
    "\n",
    "    space_id = params.get(\"space_id\")\n",
    "    vector_index_id = params.get(\"vector_index_id\")\n",
    "\n",
    "    def proximity_search( query, api_client ):\n",
    "        document_search_tool = Toolkit(\n",
    "            api_client=api_client\n",
    "        ).get_tool(\"RAGQuery\")\n",
    "\n",
    "\n",
    "        config = {\n",
    "        \"vectorIndexId\": vector_index_id,\n",
    "        \"spaceId\": space_id\n",
    "        }\n",
    "\n",
    "    def get_api_client(context):\n",
    "        credentials = Credentials(\n",
    "            url=\"https://au-syd.ml.cloud.ibm.com\",\n",
    "            token=context.get_token()\n",
    "        )\n",
    "\n",
    "        api_client = APIClient(\n",
    "            credentials = credentials,\n",
    "            space_id = space_id\n",
    "        )\n",
    "\n",
    "        return api_client\n",
    "\n",
    "    def text_detection(context, text, detectors):\n",
    "        if (not text):\n",
    "            return []\n",
    "        body = {\n",
    "            \"detectors\": detectors,\n",
    "            \"input\": text,\n",
    "            \"space_id\": space_id\n",
    "        }\n",
    "    \n",
    "        query_params = {\n",
    "            \"version\": \"2023-05-23\"\n",
    "        }\n",
    "    \n",
    "        headers  = {\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f'Bearer {context.get_token()}'\n",
    "        }\n",
    "        \n",
    "        detection_url = \"https://private.au-syd.ml.cloud.ibm.com\"\n",
    "        \n",
    "        detection_response = requests.post(f'{detection_url}/ml/v1/text/detection', headers = headers, json = body, params = query_params)\n",
    "        \n",
    "        if (detection_response.status_code > 400):\n",
    "            raise Exception(f'Error doing text detection: {detection_response.json()}' )\n",
    "        \n",
    "        return detection_response.json().get(\"detections\")\n",
    "    \n",
    "    def moderate_stream(response_stream):\n",
    "        regex = r'^[^?.!\\n].*[?.!\\n]$'\n",
    "    \n",
    "        sentence = \"\"\n",
    "    \n",
    "        for chunk in response_stream:\n",
    "            if (len(chunk[\"choices\"])):\n",
    "                sentence = f'{sentence}{chunk[\"choices\"][0][\"delta\"][\"content\"]}'\n",
    "                if (not bool(re.match(regex, sentence))):\n",
    "                    continue\n",
    "                    \n",
    "            detectors = {\n",
    "                \"hap\": {\n",
    "                    \"enabled\": True,\n",
    "                    \"threshold\": 0.5\n",
    "                }\n",
    "            }\n",
    "    \n",
    "            detections = text_detection(context, sentence, detectors)\n",
    "    \n",
    "            if (len(detections)):\n",
    "                for detection in detections:\n",
    "                    if (detection[\"detection_type\"] == \"pii\"):\n",
    "                        sentence = sentence.replace(detection[\"text\"], \"[Possibly personal information removed]\")\n",
    "                    elif (detection[\"detection_type\"] == \"hap\"):\n",
    "                        sentence = sentence.replace(detection[\"text\"], \"[Potentially harmful text removed]\")\n",
    "            \n",
    "            chunk_response = {\n",
    "                \"choices\": [{\n",
    "                    \"index\": 0,\n",
    "                    \"delta\": {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": sentence\n",
    "                    }\n",
    "                    \n",
    "                }]\n",
    "            }\n",
    "    \n",
    "            yield chunk_response\n",
    "            sentence = \"\"\n",
    "        \n",
    "    def moderation_input(mask):\n",
    "        return {\n",
    "            \"choices\": [{\n",
    "                \"index\": 0,\n",
    "                \"message\": {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": mask\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "    \n",
    "    def moderation_input_stream(mask):\n",
    "        yield {\n",
    "            \"choices\": [{\n",
    "                \"index\": 0,\n",
    "                \"delta\": {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": mask\n",
    "                }\n",
    "                \n",
    "            }]\n",
    "        }\n",
    "    \n",
    "    def get_moderation_input_mask(detections):\n",
    "        mask = \"\"\n",
    "        if (detections[0][\"detection_type\"] == \"pii\"):\n",
    "            mask = \"[The input was rejected for containing personal information].\"\n",
    "        elif (detections[0][\"detection_type\"] == \"hap\"):\n",
    "            mask = \"[The input was rejected as inappropriate].\"\n",
    "        elif (detections[0][\"detection_type\"] == \"risk\"):\n",
    "            mask = \"[The input was rejected as harmful by granite guardian].\"\n",
    "        return mask\n",
    "        \n",
    "\n",
    "    def inference_model( messages, context, stream ):\n",
    "        query = messages[-1].get(\"content\")\n",
    "        api_client = get_api_client(context)\n",
    "\n",
    "        grounding_context = proximity_search(query, api_client)\n",
    "\n",
    "        grounding = grounding_context\n",
    "        messages.insert(0, {\n",
    "            \"role\": f\"system\",\n",
    "            \"content\": f\"\"\"You are a CPL (Credit for Prior Learning) evaluation assistant for Northeastern University's Project Management program.\n",
    "\n",
    "## YOUR TASK:\n",
    "The user may ask about anything, mostly regarding a student based on NUID or student's name.\n",
    "You MUST search the grounded documents below to find information about the student.\n",
    "\n",
    "## FROM THE GROUNDED DOCUMENTS, EXTRACT:\n",
    "- student's NUID\n",
    "- student's name  \n",
    "- request_type (experience-based OR credit transfer)\n",
    "- target_course (the NU course they want credit for)\n",
    "- uploaded documents (resume, transcript, syllabus, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "## EVALUATION LOGIC:\n",
    "\n",
    "### IF request_type == \"experience\" OR \"job\" OR \"work\" OR similar:\n",
    "Analyze the RESUME document only.\n",
    "\n",
    "**For RECOMMENDATION request (user asks for \"recommendation\", \"evaluate\", \"assess\", etc.):**\n",
    "Evaluate based on these criteria:\n",
    "1. Does the student have relevant DIRECT project management experience?\n",
    "2. Does the student have MS Project experience?\n",
    "3. Does the student have at least 3 years of full-time or part-time experience?\n",
    "\n",
    "Provide:\n",
    "- AI Recommendation (3-4 sentences)\n",
    "- Decision: APPROVE or DENY\n",
    "- Justification based on the 3 criteria above\n",
    "\n",
    "**For SUMMARY request (user asks for \"summary\", \"overview\", \"details\", etc.):**\n",
    "Provide a summary (3-4 sentences in your own words) based on the metadata of documents matching the NUID.\n",
    "\n",
    "---\n",
    "\n",
    "### IF request_type == \"credit transfer\" OR \"course credit\" OR similar:\n",
    "Analyze the TRANSCRIPT and SYLLABUS documents.\n",
    "\n",
    "**Transcript Analysis Requirements:**\n",
    "- Course name must match the student's syllabus subject\n",
    "- Grade must be B or 3.0/4.0 or equivalent\n",
    "- Transcript must not be older than 5 academic years\n",
    "\n",
    "**Syllabus Comparison:**\n",
    "- Find the Northeastern University syllabus for the target_course\n",
    "- Compare student's uploaded syllabus with NU's target_course syllabus\n",
    "- Check for topic alignment, learning outcomes match\n",
    "\n",
    "**For RECOMMENDATION request:**\n",
    "- Compare student's syllabus with target_course syllabus\n",
    "- Analyze transcript grades and dates\n",
    "- Provide AI Recommendation (3-4 sentences)\n",
    "- Decision: APPROVE or DENY with justification\n",
    "\n",
    "**For SUMMARY request:**\n",
    "Provide a summary (3-4 sentences) based on the metadata of documents matching the NUID.\n",
    "\n",
    "---\n",
    "\n",
    "## RESPONSE FORMAT:\n",
    "\n",
    "Always structure your response clearly:\n",
    "\n",
    "**Student Information:**\n",
    "- Name: [extracted from documents]\n",
    "- NUID: [extracted from documents]\n",
    "- Request Type: [experience/credit transfer]\n",
    "- Target Course: [course code]\n",
    "\n",
    "**Analysis:**\n",
    "[Your analysis based on the documents]\n",
    "\n",
    "**Recommendation:** APPROVE / DENY\n",
    "**Justification:** [3-4 sentences explaining why]\n",
    "\n",
    "---\n",
    "\n",
    "## IMPORTANT RULES:\n",
    "1. ONLY use information from the grounded documents below\n",
    "2. If you cannot find the student's documents, say \"I could not find documents for this student\"\n",
    "3. If request_type is unclear, ask for clarification\n",
    "4. Be specific about which documents you analyzed\n",
    "\n",
    "---\n",
    "\n",
    "## GROUNDED DOCUMENTS FROM KNOWLEDGE BASE:\n",
    "{grounding_context}\n",
    "\n",
    "[[[don't mention about the grounded documents in the prompt response. Act like this is a production level chatbot responding!]]]\n",
    "[[[You can answer any other question based on the documents like about any syllabus document that is not related to a student i.e., northeastern university's syllabus document, and it DOES NOT NEED ANY META DATA]]]\n",
    "---\n",
    "\n",
    "\n",
    "### Context:\n",
    "{grounding}\n",
    "\n",
    "\"\"\"\n",
    "        })\n",
    "\n",
    "        # moderate input\n",
    "        system_prompt_content = \"\".join(map(lambda message: message.get(\"content\"), list(filter(lambda message: message.get(\"role\") == \"system\", messages))))\n",
    "        \n",
    "        detectors = {\n",
    "                \"hap\": {\n",
    "                    \"enabled\": True,\n",
    "                    \"threshold\": 0.5\n",
    "                }\n",
    "            }\n",
    "        detections = text_detection(context, f'{system_prompt_content}{query}', detectors)\n",
    "        if (len(detections)):\n",
    "            mask = get_moderation_input_mask(detections)\n",
    "            if (stream):\n",
    "                return moderation_input_stream(mask)\n",
    "            else:\n",
    "                return moderation_input(mask)\n",
    "            \n",
    "\n",
    "        model_id = \"meta-llama/llama-3-3-70b-instruct\"\n",
    "        parameters =  {\n",
    "            \"frequency_penalty\": 0,\n",
    "            \"max_tokens\": 2000,\n",
    "            \"presence_penalty\": 0,\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 1\n",
    "        }\n",
    "        model = ModelInference(\n",
    "            model_id = model_id,\n",
    "            api_client = api_client,\n",
    "            params = parameters\n",
    "        )\n",
    "        # Generate grounded response\n",
    "        if (stream == True):\n",
    "            generated_response = model.chat_stream(messages=messages)\n",
    "        else:\n",
    "            generated_response = model.chat(messages=messages)\n",
    "\n",
    "        return generated_response\n",
    "\n",
    "\n",
    "    def generate(context):\n",
    "        payload = context.get_json()\n",
    "        messages = payload.get(\"messages\")\n",
    "        \n",
    "        # Grounded inferencing\n",
    "        generated_response = inference_model(messages, context, False)\n",
    "\n",
    "        execute_response = {\n",
    "            \"headers\": {\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            },\n",
    "            \"body\": generated_response\n",
    "        }\n",
    "\n",
    "        return execute_response\n",
    "\n",
    "    def generate_stream(context):\n",
    "        payload = context.get_json()\n",
    "        messages = payload.get(\"messages\")\n",
    "\n",
    "        # Grounded inferencing\n",
    "        response_stream = inference_model(messages, context, True)\n",
    "\n",
    "        moderated_stream = moderate_stream(response_stream)\n",
    "\n",
    "        for chunk in moderated_stream:\n",
    "            yield chunk\n",
    "\n",
    "    return generate, generate_stream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Test locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "86b2c1d3-4b52-4b11-ae4e-c248c966138a"
   },
   "outputs": [],
   "source": [
    "# Initialize AI Service function locally\n",
    "from ibm_watsonx_ai.deployments import RuntimeContext\n",
    "\n",
    "context = RuntimeContext(api_client=client)\n",
    "\n",
    "streaming = False\n",
    "findex = 1 if streaming else 0\n",
    "local_function = gen_ai_service(context, vector_index_id=vector_index_id, space_id=space_id)[findex]\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ac2b1d85-7ffa-405c-8870-2c78bc1c5141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'headers': {'Content-Type': 'application/json'}, 'body': {'id': 'chatcmpl-7ca428b5e9489b6856c21b36576c9f0e---6b2993a8-a1c0-4532-9ce5-c45c4950f2ec', 'object': 'chat.completion', 'model_id': 'meta-llama/llama-3-3-70b-instruct', 'model': 'meta-llama/llama-3-3-70b-instruct', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"I'm ready to help. What is the student's NUID or name you would like me to look up?\"}, 'finish_reason': 'stop'}], 'created': 1764262077, 'model_version': '3.3.0', 'created_at': '2025-11-27T16:47:57.791Z', 'usage': {'completion_tokens': 24, 'prompt_tokens': 785, 'total_tokens': 809}, 'system': {'warnings': [{'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL.', 'id': 'disclaimer_warning', 'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx'}]}}}\n"
     ]
    }
   ],
   "source": [
    "local_question = \"Change this question to test your function\"\n",
    "\n",
    "messages.append({ \"role\" : \"user\", \"content\": local_question })\n",
    "\n",
    "context = RuntimeContext(api_client=client, request_payload_json={\"messages\": messages})\n",
    "\n",
    "response = local_function(context)\n",
    "\n",
    "result = ''\n",
    "\n",
    "if (streaming):\n",
    "    for chunk in response:\n",
    "        if (len(chunk[\"choices\"])):\n",
    "            print(chunk[\"choices\"][0][\"delta\"][\"content\"], end=\"\", flush=True)\n",
    "else:\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Store and deploy the AI Service\n",
    "Before you can deploy the AI Service, you must store the AI service in your watsonx.ai repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5a647e3e-13d8-4c0e-94be-d52714c3158e"
   },
   "outputs": [],
   "source": [
    "# Look up software specification for the AI service\n",
    "software_spec_id_in_project = \"45f12dfe-aa78-5b8d-9f38-0ee223c47309\"\n",
    "software_spec_id = \"\"\n",
    "\n",
    "try:\n",
    "    software_spec_id = client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")\n",
    "except:\n",
    "    software_spec_id = client.spaces.promote(software_spec_id_in_project, source_project_id, space_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "feb29c22-0323-4ac8-ab7c-05d983093a65"
   },
   "outputs": [],
   "source": [
    "# Define the request and response schemas for the AI service\n",
    "request_schema = {\n",
    "    \"application/json\": {\n",
    "        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"messages\": {\n",
    "                \"title\": \"The messages for this chat session.\",\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"role\": {\n",
    "                            \"title\": \"The role of the message author.\",\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": [\"user\",\"assistant\"]\n",
    "                        },\n",
    "                        \"content\": {\n",
    "                            \"title\": \"The contents of the message.\",\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"role\",\"content\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"messages\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "response_schema = {\n",
    "    \"application/json\": {\n",
    "        \"oneOf\": [{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service_stream\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices.\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"title\":\"The index of this result.\"},\"delta\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"content\":{\"description\":\"The contents of the message.\",\"type\":\"string\"},\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]},{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"description\":\"The index of this result.\"},\"message\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"},\"content\":{\"title\":\"Message content.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]}]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "b2ba0468-9184-461c-bd4f-462f7139ed9a"
   },
   "outputs": [],
   "source": [
    "# Store the AI service in the repository\n",
    "ai_service_metadata = {\n",
    "    client.repository.AIServiceMetaNames.NAME: \"CPL Rag Notebook\",\n",
    "    client.repository.AIServiceMetaNames.DESCRIPTION: \"\",\n",
    "    client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: software_spec_id,\n",
    "    client.repository.AIServiceMetaNames.CUSTOM: {},\n",
    "    client.repository.AIServiceMetaNames.REQUEST_DOCUMENTATION: request_schema,\n",
    "    client.repository.AIServiceMetaNames.RESPONSE_DOCUMENTATION: response_schema,\n",
    "    client.repository.AIServiceMetaNames.TAGS: [\"wx-vector-index\"]\n",
    "}\n",
    "\n",
    "ai_service_details = client.repository.store_ai_service(meta_props=ai_service_metadata, ai_service=gen_ai_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "9e70c5af-093b-4ef5-beb8-c3020f380594"
   },
   "outputs": [],
   "source": [
    "# Get the AI Service ID\n",
    "\n",
    "ai_service_id = client.repository.get_ai_service_id(ai_service_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "e2322d67-1e66-4a96-9dbf-fecb2f65514c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "######################################################################################\n",
      "\n",
      "Synchronous deployment creation for id: 'ab4fe104-a8d3-4f8e-9242-0a4ab17186e4' started\n",
      "\n",
      "######################################################################################\n",
      "\n",
      "\n",
      "initializing\n",
      "Note: online_url and serving_urls are deprecated and will be removed in a future release. Use inference instead.\n",
      "...\n",
      "ready\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_id='a89ff2b2-73b6-475d-adc9-83fcaa612085'\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deploy the stored AI Service\n",
    "deployment_custom = {}\n",
    "deployment_metadata = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"CPL Rag Notebook\",\n",
    "    client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
    "    client.deployments.ConfigurationMetaNames.CUSTOM: deployment_custom,\n",
    "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"\",\n",
    "    client.repository.AIServiceMetaNames.TAGS: [\"wx-vector-index\"]\n",
    "}\n",
    "\n",
    "function_deployment_details = client.deployments.create(ai_service_id, meta_props=deployment_metadata, space_id=space_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test AI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "9c4c09d5-8657-4846-b8fc-af16ba78f4b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a89ff2b2-73b6-475d-adc9-83fcaa612085\n"
     ]
    }
   ],
   "source": [
    "# Get the ID of the AI Service deployment just created\n",
    "\n",
    "deployment_id = client.deployments.get_id(function_deployment_details)\n",
    "print(deployment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "b9259718-93a5-4558-893f-43aafc7e2fb7"
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "remote_question = \"Tell me about John Smith's experience\"\n",
    "messages.append({ \"role\" : \"user\", \"content\": remote_question })\n",
    "payload = { \"messages\": messages }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "9624dfa1-1907-40c6-8054-1cba843c78d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': '**Student Information:**\\n- Name: John Smith\\n- NUID: Not available\\n- Request Type: Experience-based\\n- Target Course: Not specified\\n\\n**Analysis:**\\nI could not find documents for John Smith. To provide an accurate analysis, I would need access to his resume and other relevant documents.\\n\\nIf you could provide more context or clarify which documents are available for John Smith, I would be happy to try and assist you further.', 'role': 'assistant'}}], 'created': 1764262252, 'created_at': '2025-11-27T16:50:54.133Z', 'id': 'chatcmpl-34d53695d6ee9e8703d1fbd7f8dbe6b0---f22e270f-99a6-44d0-a556-67e276b1f8a3', 'model': 'meta-llama/llama-3-3-70b-instruct', 'model_id': 'meta-llama/llama-3-3-70b-instruct', 'model_version': '3.3.0', 'object': 'chat.completion', 'system': {'warnings': [{'id': 'disclaimer_warning', 'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL.', 'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx'}]}, 'usage': {'completion_tokens': 91, 'prompt_tokens': 785, 'total_tokens': 876}}\n"
     ]
    }
   ],
   "source": [
    "result = client.deployments.run_ai_service(deployment_id, payload)\n",
    "if \"error\" in result:\n",
    "    print(result[\"error\"])\n",
    "else:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "You successfully deployed and tested the AI Service! You can now view\n",
    "your deployment and test it as a REST API endpoint.\n",
    "\n",
    "<a id=\"copyrights\"></a>\n",
    "### Copyrights\n",
    "\n",
    "Licensed Materials - Copyright © 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\n",
    "Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n",
    "\n",
    "**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n",
    "\n",
    "By downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
